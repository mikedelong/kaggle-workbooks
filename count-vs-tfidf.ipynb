{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from wordcloud import STOPWORDS\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ndef get_counts(column: str) -> pd.DataFrame:\n    min_df = 10\n    stop_words = list(STOPWORDS) + ['aren', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn']\n    count_vectorizer = CountVectorizer(stop_words=stop_words, min_df=min_df)\n    tfidf = TfidfVectorizer(stop_words=stop_words, min_df=min_df)\n    raw_documents = df[column].fillna('').values.tolist()\n    raw_documents = [item for item in raw_documents if item != '']\n    tfidf_result = tfidf.fit_transform(raw_documents=raw_documents)\n    tfidf_df = pd.DataFrame(tfidf_result.toarray(), columns = tfidf.get_feature_names_out()).sum(axis=0).to_frame().reset_index().rename(columns={'index': 'token', 0 : 'tfidf'})\n    count_result = count_vectorizer.fit_transform(raw_documents=raw_documents)\n    count_df = pd.DataFrame(count_result.toarray(), columns =  count_vectorizer.get_feature_names_out()).sum(axis=0).to_frame().reset_index().rename(columns={'index': 'token', 0 : 'count'})\n    return count_df.merge(right=tfidf_df, on='token', how='inner')\n","metadata":{},"execution_count":null,"outputs":[]}]}