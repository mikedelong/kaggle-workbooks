{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is an exploration of the whole series of mortality data from the CDC.\n\nFirst let's configure logging, including turning off the preconfigured loggers.","metadata":{}},{"cell_type":"code","source":"from logging import Formatter\nfrom logging import getLogger\nfrom logging import INFO\nfrom logging import StreamHandler\n\nlogger = getLogger(__name__)\nlogger.handlers.clear()\nhandler = StreamHandler()\nhandler.setLevel(INFO)\nhandler.setFormatter(Formatter('%(name)s - %(asctime)s - %(levelname)s - %(message)s'))\nlogger.addHandler(handler)","metadata":{"execution":{"iopub.status.busy":"2023-06-15T17:35:31.981174Z","iopub.execute_input":"2023-06-15T17:35:31.981637Z","iopub.status.idle":"2023-06-15T17:35:31.990086Z","shell.execute_reply.started":"2023-06-15T17:35:31.981607Z","shell.execute_reply":"2023-06-15T17:35:31.988943Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"Let's list all the files. We note that we have data files in CSV format representing the years 2005-2015, inclusive (11 years).","metadata":{}},{"cell_type":"code","source":"from os import walk\nfrom os.path import join\n\nfor dirname, _, filenames in walk('../input/mortality/'):\n    for filename in filenames:\n        logger.info(msg=join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-06-15T17:35:32.002120Z","iopub.execute_input":"2023-06-15T17:35:32.002560Z","iopub.status.idle":"2023-06-15T17:35:32.040143Z","shell.execute_reply.started":"2023-06-15T17:35:32.002525Z","shell.execute_reply":"2023-06-15T17:35:32.038868Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stderr","text":"__main__ - 2023-06-15 17:35:32,009 - INFO - ../input/mortality/2014_codes.json\n__main__ - 2023-06-15 17:35:32,011 - INFO - ../input/mortality/2007_data.csv\n__main__ - 2023-06-15 17:35:32,012 - INFO - ../input/mortality/2007_codes.json\n__main__ - 2023-06-15 17:35:32,013 - INFO - ../input/mortality/2012_data.csv\n__main__ - 2023-06-15 17:35:32,014 - INFO - ../input/mortality/2010_data.csv\n__main__ - 2023-06-15 17:35:32,015 - INFO - ../input/mortality/2009_data.csv\n__main__ - 2023-06-15 17:35:32,016 - INFO - ../input/mortality/2011_data.csv\n__main__ - 2023-06-15 17:35:32,018 - INFO - ../input/mortality/2015_codes.json\n__main__ - 2023-06-15 17:35:32,019 - INFO - ../input/mortality/2011_codes.json\n__main__ - 2023-06-15 17:35:32,020 - INFO - ../input/mortality/2006_data.csv\n__main__ - 2023-06-15 17:35:32,021 - INFO - ../input/mortality/2010_codes.json\n__main__ - 2023-06-15 17:35:32,022 - INFO - ../input/mortality/2005_data.csv\n__main__ - 2023-06-15 17:35:32,023 - INFO - ../input/mortality/2008_codes.json\n__main__ - 2023-06-15 17:35:32,024 - INFO - ../input/mortality/2013_codes.json\n__main__ - 2023-06-15 17:35:32,026 - INFO - ../input/mortality/2005_codes.json\n__main__ - 2023-06-15 17:35:32,026 - INFO - ../input/mortality/2014_data.csv\n__main__ - 2023-06-15 17:35:32,029 - INFO - ../input/mortality/2013_data.csv\n__main__ - 2023-06-15 17:35:32,030 - INFO - ../input/mortality/2015_data.csv\n__main__ - 2023-06-15 17:35:32,031 - INFO - ../input/mortality/2012_codes.json\n__main__ - 2023-06-15 17:35:32,032 - INFO - ../input/mortality/2009_codes.json\n__main__ - 2023-06-15 17:35:32,033 - INFO - ../input/mortality/2008_data.csv\n__main__ - 2023-06-15 17:35:32,035 - INFO - ../input/mortality/2006_codes.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from json import load\nwith open(file='../input/mortality/2013_codes.json', mode='r', encoding='utf-8', ) as codes_fp:\n    codes = load(fp=codes_fp,)\n    \nfor key in codes.keys():\n    logger.info(msg=key)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-15T17:35:32.042737Z","iopub.execute_input":"2023-06-15T17:35:32.043168Z","iopub.status.idle":"2023-06-15T17:35:32.090920Z","shell.execute_reply.started":"2023-06-15T17:35:32.043135Z","shell.execute_reply":"2023-06-15T17:35:32.089743Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stderr","text":"__main__ - 2023-06-15 17:35:32,048 - INFO - resident_status\n__main__ - 2023-06-15 17:35:32,049 - INFO - education_1989_revision\n__main__ - 2023-06-15 17:35:32,050 - INFO - education_2003_revision\n__main__ - 2023-06-15 17:35:32,051 - INFO - education_reporting_flag\n__main__ - 2023-06-15 17:35:32,052 - INFO - month_of_death\n__main__ - 2023-06-15 17:35:32,052 - INFO - sex\n__main__ - 2023-06-15 17:35:32,054 - INFO - age_substitution_flag\n__main__ - 2023-06-15 17:35:32,056 - INFO - age_recode_52\n__main__ - 2023-06-15 17:35:32,057 - INFO - age_recode_27\n__main__ - 2023-06-15 17:35:32,057 - INFO - age_recode_12\n__main__ - 2023-06-15 17:35:32,059 - INFO - infant_age_recode_22\n__main__ - 2023-06-15 17:35:32,060 - INFO - place_of_death_and_decedents_status\n__main__ - 2023-06-15 17:35:32,060 - INFO - marital_status\n__main__ - 2023-06-15 17:35:32,061 - INFO - day_of_week_of_death\n__main__ - 2023-06-15 17:35:32,062 - INFO - current_data_year\n__main__ - 2023-06-15 17:35:32,063 - INFO - injury_at_work\n__main__ - 2023-06-15 17:35:32,064 - INFO - manner_of_death\n__main__ - 2023-06-15 17:35:32,065 - INFO - method_of_disposition\n__main__ - 2023-06-15 17:35:32,066 - INFO - autopsy\n__main__ - 2023-06-15 17:35:32,067 - INFO - activity_code\n__main__ - 2023-06-15 17:35:32,068 - INFO - place_of_injury_for_causes_w00_y34_except_y06_and_y07_\n__main__ - 2023-06-15 17:35:32,069 - INFO - icd_code_10th_revision\n__main__ - 2023-06-15 17:35:32,070 - INFO - 358_cause_recode\n__main__ - 2023-06-15 17:35:32,071 - INFO - 113_cause_recode\n__main__ - 2023-06-15 17:35:32,076 - INFO - 130_infant_cause_recode\n__main__ - 2023-06-15 17:35:32,077 - INFO - 39_cause_recode\n__main__ - 2023-06-15 17:35:32,078 - INFO - race\n__main__ - 2023-06-15 17:35:32,079 - INFO - bridged_race_flag\n__main__ - 2023-06-15 17:35:32,080 - INFO - race_imputation_flag\n__main__ - 2023-06-15 17:35:32,081 - INFO - race_recode_3\n__main__ - 2023-06-15 17:35:32,082 - INFO - race_recode_5\n__main__ - 2023-06-15 17:35:32,084 - INFO - hispanic_origin\n__main__ - 2023-06-15 17:35:32,085 - INFO - hispanic_originrace_recode\n__main__ - 2023-06-15 17:35:32,086 - INFO - detail_age_type\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If we try to load up all of the data we may run out of memory, so let's start by doing one big load of just the columns we initially want across all 11 years; we'll use a list comprehension and concat() to avoid saving two copies of the data, and we'll hide the progress information in our CSV reading code. We have one year where one column is named differently, so we have to modify the used columns based on the year.","metadata":{}},{"cell_type":"code","source":"from pandas import concat\nfrom pandas import read_csv\nfrom pandas import DataFrame\n\nUSECOLS = ['activity_code', 'autopsy', 'current_data_year', 'day_of_week_of_death', 'detail_age', 'education_reporting_flag',\n           'injury_at_work', 'manner_of_death', 'marital_status', 'method_of_disposition', 'month_of_death', \n           'place_of_death_and_decedents_status', 'race', 'resident_status', 'sex']\n\ndef get_usecols(year: int) -> list:\n    return sorted(USECOLS + ['icd_code_10th_revision']) if year != 2012 else sorted(USECOLS + ['icd_code_10'])\n\ndef read(filename: str, usecols: list, ) -> DataFrame:\n    logger = getLogger(name=__name__)\n    logger.info(msg='reading {}'.format(filename))\n    result_df = read_csv(filepath_or_buffer=filename, low_memory=False, usecols=usecols, )\n    if 'icd_code_10' in result_df.columns:\n        result_df = result_df.rename(columns={'icd_code_10': 'icd_code_10th_revision'})\n    logger.info(msg='read {} rows.'.format(len(result_df)))\n    logger.debug(msg=result_df.columns)\n    return result_df\n\ndf = concat([read(filename='../input/mortality/{}_data.csv'.format(year),\n                  usecols=get_usecols(year), ) for year in range(2005, 2016)])","metadata":{"execution":{"iopub.status.busy":"2023-06-15T17:35:32.092411Z","iopub.execute_input":"2023-06-15T17:35:32.092769Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"__main__ - 2023-06-15 17:35:32,100 - INFO - reading ../input/mortality/2005_data.csv\n__main__ - 2023-06-15 17:35:46,292 - INFO - read 2452506 rows.\n__main__ - 2023-06-15 17:35:46,294 - INFO - reading ../input/mortality/2006_data.csv\n__main__ - 2023-06-15 17:36:00,153 - INFO - read 2430725 rows.\n__main__ - 2023-06-15 17:36:00,154 - INFO - reading ../input/mortality/2007_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Let's see how much data we have.","metadata":{}},{"cell_type":"code","source":"logger.info(msg='row count: {}'.format(len(df)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's make our first graph: a plot of the total deaths for each year.\nAnd let's use lmplot() to include a trend line.","metadata":{}},{"cell_type":"code","source":"from seaborn import lmplot\n%matplotlib inline\nannual_total_df = df['current_data_year'].value_counts().to_frame(name='deaths').reset_index()\nannual_total_df.columns = ['year', 'deaths']\nlmplot(data=annual_total_df, x='year', y='deaths',)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's try splitting out male and female deaths.","metadata":{}},{"cell_type":"code","source":"lmplot(col='sex', \n       data=df.groupby(by=['current_data_year', 'sex']).size().reset_index().rename(columns={'current_data_year': 'year', 0: 'deaths'}),\n       x='year', y='deaths',)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's get the race names, add a column for the race name, and split out the deaths by race.","metadata":{}},{"cell_type":"code","source":"codes = {key: value for key, value in codes.items() if key in df.columns}\ndf['race_name'] = df['race'].replace(to_replace={int(key): value for key, value in codes['race'].items()})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lmplot(data=df.groupby(by=['current_data_year', 'race_name']).size().reset_index().rename(columns={'current_data_year': 'year', 0: 'deaths'}),\n       facet_kws=dict(sharey=False), col='race_name', seed=1, col_wrap=2,\n       x='year', y='deaths',)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger.info(msg=codes.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger.info(msg='done')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}